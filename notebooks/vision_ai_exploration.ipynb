{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision AI Showcase - Exploration Notebook\n",
    "\n",
    "This notebook demonstrates how to use the Vision AI Showcase framework for computer vision tasks.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Configuration\n",
    "2. Model Registry Overview\n",
    "3. Loading and Preprocessing Data\n",
    "4. Running Inference\n",
    "5. Visualizing Results\n",
    "6. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path('../').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from src.models.registry import ModelRegistry\n",
    "from src.inference.pipeline import InferencePipeline\n",
    "from src.data.loaders import ImageDataLoader\n",
    "from src.utils.config import ConfigManager\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_manager = ConfigManager('../configs/default.yaml')\n",
    "config = config_manager.get_config()\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Registry Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model registry\n",
    "registry = ModelRegistry('../models')\n",
    "\n",
    "# Create default models if none exist\n",
    "if len(registry) == 0:\n",
    "    print(\"No models found. Creating default models...\")\n",
    "    registry.create_default_models()\n",
    "\n",
    "print(f\"Number of available models: {len(registry)}\")\n",
    "print(\"\\nAvailable models:\")\n",
    "for model_name in registry.get_available_models():\n",
    "    info = registry.get_model_info(model_name)\n",
    "    description = info['config'].get('description', 'No description')\n",
    "    num_classes = info['config'].get('num_classes', 'Unknown')\n",
    "    architecture = info['config'].get('architecture', 'Custom')\n",
    "    print(f\"  - {model_name}: {description}\")\n",
    "    print(f\"    Architecture: {architecture}, Classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images\n",
    "data_loader = ImageDataLoader('../data/samples')\n",
    "image_info = data_loader.get_image_info()\n",
    "\n",
    "print(\"Dataset information:\")\n",
    "print(f\"  Total images: {image_info['num_images']}\")\n",
    "print(f\"  File extensions: {image_info['extensions']}\")\n",
    "print(f\"  Average size: {image_info['avg_width']}x{image_info['avg_height']}\")\n",
    "\n",
    "if image_info['sample_paths']:\n",
    "    print(f\"  Sample files: {image_info['sample_paths'][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "if data_loader.image_paths:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    num_images = min(6, len(data_loader.image_paths))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        image_path = data_loader.image_paths[i]\n",
    "        image = data_loader.load_single_image(image_path)\n",
    "        \n",
    "        if image:\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(f\"{image_path.name}\\n{image.size[0]}x{image.size[1]}\")\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, 'Failed to load', ha='center', va='center')\n",
    "            axes[i].set_title(f\"{image_path.name} (Error)\")\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(num_images, 6):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Dataset')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"No sample images found. Please run the sample image generation script first:\")\n",
    "    print(\"python ../scripts/generate_sample_images.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model for inference\n",
    "model_name = \"imagenet_resnet50\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "try:\n",
    "    model = registry.load_model(model_name)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    # Display model information\n",
    "    model_info = model.get_model_info()\n",
    "    print(f\"\\nModel Information:\")\n",
    "    print(f\"  Name: {model_info['name']}\")\n",
    "    print(f\"  Total Parameters: {model_info['total_parameters']:,}\")\n",
    "    print(f\"  Device: {model_info['device']}\")\n",
    "    print(f\"  Input Size: {model_info['input_size']}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(f\"Available models: {registry.get_available_models()}\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference pipeline and run predictions\n",
    "if model and data_loader.image_paths:\n",
    "    pipeline = InferencePipeline(model)\n",
    "    \n",
    "    # Select first image for prediction\n",
    "    test_image_path = data_loader.image_paths[0]\n",
    "    print(f\"Running inference on: {test_image_path.name}\")\n",
    "    \n",
    "    # Load and display the image\n",
    "    test_image = data_loader.load_single_image(test_image_path)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(test_image)\n",
    "    plt.title(f\"Test Image: {test_image_path.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Run prediction\n",
    "    try:\n",
    "        result = pipeline.predict_single_pil(test_image)\n",
    "        \n",
    "        print(f\"\\nPrediction Results:\")\n",
    "        print(f\"  Inference Time: {result.get('inference_time', 'N/A'):.4f} seconds\")\n",
    "        print(f\"  Top Prediction: {result.get('top_class', 'Unknown')}\")\n",
    "        print(f\"  Confidence: {result.get('top_confidence', 0):.4f}\")\n",
    "        \n",
    "        # Display top predictions if available\n",
    "        predictions = result.get('predictions', [])\n",
    "        if predictions:\n",
    "            print(f\"\\n  Top 5 Predictions:\")\n",
    "            for pred in predictions:\n",
    "                print(f\"    {pred['rank']}. {pred['class_name']}: {pred['percentage']:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\nelse:\n",
    "    print(\"Skipping inference: model not loaded or no test images available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inference on multiple images\n",
    "if model and len(data_loader.image_paths) > 1:\n",
    "    print(\"Running batch inference...\")\n",
    "    \n",
    "    # Limit to first 4 images for visualization\n",
    "    test_paths = data_loader.image_paths[:4]\n",
    "    results = pipeline.predict_batch([str(path) for path in test_paths])\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (image_path, result) in enumerate(zip(test_paths, results)):\n",
    "        if i >= 4:\n",
    "            break\n",
    "            \n",
    "        # Load and display image\n",
    "        image = data_loader.load_single_image(image_path)\n",
    "        axes[i].imshow(image)\n",
    "        \n",
    "        # Add prediction as title\n",
    "        if 'top_class' in result:\n",
    "            title = f\"{image_path.name}\\n{result['top_class']} ({result['top_confidence']:.2f})\"\n",
    "        else:\n",
    "            title = f\"{image_path.name}\\n(Prediction failed)\"\n",
    "        \n",
    "        axes[i].set_title(title, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Batch Inference Results', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    successful_predictions = sum(1 for r in results if 'top_class' in r)\n",
    "    avg_inference_time = np.mean([r.get('inference_time', 0) for r in results if 'inference_time' in r])\n",
    "    \n",
    "    print(f\"\\nBatch Inference Summary:\")\n",
    "    print(f\"  Successful predictions: {successful_predictions}/{len(results)}\")\n",
    "    print(f\"  Average inference time: {avg_inference_time:.4f} seconds\")\n",
    "    print(f\"  Throughput: {1/avg_inference_time:.2f} images/second\")\nelse:\n",
    "    print(\"Skipping batch inference visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "if model and data_loader.image_paths:\n",
    "    print(\"Running performance benchmark...\")\n",
    "    \n",
    "    # Use subset of images for benchmarking\n",
    "    benchmark_paths = [str(path) for path in data_loader.image_paths[:5]]  # Limit for demo\n",
    "    \n",
    "    try:\n",
    "        benchmark_results = pipeline.benchmark_model(benchmark_paths, num_runs=2)\n",
    "        \n",
    "        print(f\"\\nBenchmark Results:\")\n",
    "        print(f\"  Test Images: {benchmark_results['num_test_images']}\")\n",
    "        print(f\"  Total Predictions: {benchmark_results['total_predictions']}\")\n",
    "        print(f\"  Average Time: {benchmark_results['average_inference_time']:.4f}s\")\n",
    "        print(f\"  Min Time: {benchmark_results['min_inference_time']:.4f}s\")\n",
    "        print(f\"  Max Time: {benchmark_results['max_inference_time']:.4f}s\")\n",
    "        print(f\"  Throughput: {benchmark_results['images_per_second']:.2f} images/second\")\n",
    "        \n",
    "        # Visualize timing distribution\n",
    "        times = [benchmark_results['min_inference_time'], \n",
    "                benchmark_results['average_inference_time'],\n",
    "                benchmark_results['max_inference_time']]\n",
    "        labels = ['Min', 'Average', 'Max']\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        bars = plt.bar(labels, times, color=['green', 'blue', 'red'], alpha=0.7)\n",
    "        plt.ylabel('Inference Time (seconds)')\n",
    "        plt.title('Model Performance Benchmark')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, time_val in zip(bars, times):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                    f'{time_val:.3f}s', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Benchmark failed: {e}\")\nelse:\n",
    "    print(\"Skipping benchmark: model not loaded or no test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploring Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models on the same image\n",
    "if data_loader.image_paths:\n",
    "    test_image_path = data_loader.image_paths[0]\n",
    "    test_image = data_loader.load_single_image(test_image_path)\n",
    "    \n",
    "    model_comparison = []\n",
    "    \n",
    "    # Test each available model\n",
    "    for model_name in registry.get_available_models():\n",
    "        print(f\"Testing model: {model_name}\")\n",
    "        try:\n",
    "            model = registry.load_model(model_name)\n",
    "            pipeline = InferencePipeline(model)\n",
    "            result = pipeline.predict_single_pil(test_image)\n",
    "            \n",
    "            model_comparison.append({\n",
    "                'model_name': model_name,\n",
    "                'prediction': result.get('top_class', 'N/A'),\n",
    "                'confidence': result.get('top_confidence', 0),\n",
    "                'inference_time': result.get('inference_time', 0),\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            model_comparison.append({\n",
    "                'model_name': model_name,\n",
    "                'error': str(e),\n",
    "                'success': False\n",
    "            })\n",
    "    \n",
    "    # Display comparison results\n",
    "    print(f\"\\nModel Comparison Results for {test_image_path.name}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for comp in model_comparison:\n",
    "        if comp['success']:\n",
    "            print(f\"Model: {comp['model_name']}\")\n",
    "            print(f\"  Prediction: {comp['prediction']}\")\n",
    "            print(f\"  Confidence: {comp['confidence']:.4f}\")\n",
    "            print(f\"  Time: {comp['inference_time']:.4f}s\")\n",
    "        else:\n",
    "            print(f\"Model: {comp['model_name']} - FAILED\")\n",
    "            print(f\"  Error: {comp['error']}\")\n",
    "        print()\nelse:\n",
    "    print(\"No test images available for model comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vision AI Showcase Exploration Complete!\")\nprint(\"\\n\" + \"=\"*50)\nprint(\"SUMMARY\")\nprint(\"=\"*50)\nprint(f\"✓ Loaded configuration from: {config_manager.config_path}\")\nprint(f\"✓ Available models: {len(registry)}\")\nprint(f\"✓ Sample images: {len(data_loader.image_paths)}\")\nprint(f\"✓ PyTorch device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\nprint(\"\\nNext Steps:\")\nprint(\"1. Try the web interface: streamlit run ../app.py\")\nprint(\"2. Use the CLI: python ../main.py --mode demo\")\nprint(\"3. Add your own images to ../data/samples/\")\nprint(\"4. Create custom models by extending BaseModel\")\nprint(\"5. Explore the scripts in ../scripts/\")\nprint(\"\\nFor more information, check the README.md file!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}